\subsection{Error Bars and Optimality}\label{subsec:correct-practical}
The only terms in the correction that are not deterministic is $\dans$ and $\dans_{cnt}$.
For the \sumfunc, \countfunc, and \avgfunc queries, we can bound these terms in error bars thus giving us error bars for the entire expression (refer to \cite{wang1999sample} on how to do this).
The intuition is that we can rewrite the term $\dans$ as a mean value of uniformly randomly sampled records.
By the Central Limit Theorem, the mean value of numbers drawn by uniform random sampling $\bar{X}$ approaches a normal distribution with:
\[
\bar{X} \sim N(\mu,\frac{\sigma^2}{k}),
\]
where $\mu$ is the true mean, $\sigma^2$ is the variance, and $k$ is the sample size. \footnote{For sampling without replacement, there is an additional term of $\sqrt{\frac{N-k}{N-1}}$. We consider estimates where N is large in comparison to k making this term insignificant.}
We can use this to bound the term with its 95\% confidence interval (or any other user specified probability), e.g., $\bar{X} \pm 1.96 \frac{\sigma}{\sqrt{k}}$.
Since the estimate is unbiased, the confidence interval indicates that the true value lies in the confidence interval with the specified probability.

We can prove that for the \sumfunc, \countfunc, and \avgfunc queries this estimate is optimal with respect to the variance.
\begin{proposition}
An estimator is called a minimum variance unbiased estimator (MVUE) of a parameter if it is unbiased and the variance of the parameter estimate is less than or equal to that of any other unbiased estimator of the parameter.
\end{proposition}
The concept of a Minimum Variance Unbiased Estimator (MVUE) comes from statistical decision theory \cite{cox1979theoretical}.
Unbiased estimators are ones that, in expectation, are correct.
However, on its own, the concept of an unbiased estimate is not useful as we can construct bad unbiased estimates.
For example, if we simply pick a random element from a set, it is still an unbiased estimate of the mean of the set.
The variance of the estimate determines the size of our confidence intervals thus is important to consider.

The \sumfunc, \countfunc, and \avgfunc queries are linear functions of their input rows.
We explored whether our estimate was optimal for linear estimates, for example, should we weight our functions when applied to the sample.
It turns out that the proposed corrections are the optimal strategy when nothing is known about the data distribution a priori.

\begin{theorem}
For \sumfunc, \countfunc, and \avgfunc queries, our estimate of the correction is optimal over the class of linear estimators when no other information is known about the distribution. 
In other words, there exists no other linear function of the set input rows $\{ X_i \}$ that gives a lower variance correction.
\end{theorem}
\begin{proof}
\emph{Sketch: } We can reformulate \sumfunc, \countfunc, and \avgfunc as means over the entire table. \sumfunc is the mean multiplied by the dataset size, and \countfunc
is the sum where all the records have been set to 1. Then, we prove the theorem by induction. 
Suppose, we have two independent estimates of the mean $\bar{X}_1$ and $\bar{X}_2$ with unknown variance and we want to merge them into one estimate $\bar{X} = c_1\bar{X}_1+c_2\bar{X}_2$.
Since, we do not know anything about the distribution by symmetry $c_1 = c_2 = 0.5$. 
Thus we can recursively induct, and we find that if we do not know the variance of data, as is impossible with new updates, then equally weighting all input rows is optimal. 
\end{proof}

\section{Extensions}
\subsection{Select Queries}\label{sec:sel}
We can correct stale Selection queries with SVC.
For \fjview and \spview, a stale selection query is missing rows.
To correct this result, we can apply the query to the update pattern sample, we get a sample of records that satisfy the predicate.
Then, we can take a union of the sampled selection and the stale selection.
To quantify the approximation error, we can rewrite the Select query as \countfunc to get an estimate of the up-to-date size of the result; giving us a bound on the number of missing rows.

For \aggview, stale selection queries can also have out-of-date rows as well as missing rows.
In this case, we can still apply the query to the update pattern sample and get a sample of rows to update and new rows to insert.
For the updated rows in the sample, we overwrite the out-of-date rows in the stale query result.
To quantify the approximation error, we can give two bounds.
As before, we can bound the number of missing rows in the result with a \countfunc query.
We further can bound the number of existing rows that are not up-to-date with a \countfunc query.

%Of course, this approach is not suited for highly selective queries which are unlikely to have sufficient representation in a sample.
In comparison to no maintenance, this approach gives a less stale result.
SAQP is limited in its support of Selection queries.
For example, if we had a 1\% sample, we could only get 1\% of the rows in the result.
In comparison, for a 1\% sample, we take advantage of the existing stale result allowing us to combine to old result with 1\% of the newly inserted records; thus including a much greater portion of the result rows.

\subsection{Deletions}\label{sec:del}
\reminder{TODO}
