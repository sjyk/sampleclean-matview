\section{Outlier Indexing}\label{outlier}
Sampling is known to be sensitive to outliers \cite{clauset2009power, chaudhuri2001overcoming}.
SVC may be sensitive to power-laws and other long-tailed distributions which are common in large datasets\cite{clauset2009power}.
Since outliers may occur very rarely, they are unlikely to be represented in a small sample. 
We address this problem using a technique called outlier indexing which has been applied in SAQP \cite{chaudhuri2001overcoming}.
The basic idea is that we create an index of outlier records and ensure that these records are included in the sample.
However, as this has not been explored in the materialized view setting there are new challenges in using this index for improved result accuracy.

\subsection{Indices on the Base Relations}
In SVC, we cannot index the sample in the same way as \cite{chaudhuri2001overcoming}. 
This is because we only materialize the sample view and we have no idea about outliers outside of this sample.
Instead, we propose building indices on the base relations.

The first step is that the user selects an attribute of any base relation to index and specifies a threshold $t$ and a size limit $k$.
In a single pass of updates (without maintaining the view), the index is built storing references to the records with attributes greater than $t$.
If the size limit is reached, the incoming record is compared to the smallest indexed record and if it is greater then we evict the smallest record.
The same approach can be extended to attributes that have tails in both directions by making the threshold $t$ a range, which takes the highest and the lowest values.
However, in this section, we present the technique as a threshold for clarity.

To select the threshold, there are many heuristics that we can use.
For example, we can use our knowledge about the dataset to set a threshold.
Or we can use prior information from the base table, a calculation which can be done in the background during the periodic maintenance cycles.
If our size limit is $k$, we can find the records with the top $k$ attributes in the base table as to set a threshold to maximally fill up our index. 
Then, the attribute value of the lowest record becomes the threshold $t$.

\subsection{Adding Outliers to the Sample}
Given this index, the next question is how we can use this information in our materialized views.
We ensure that any row in a materialized view that derives from an indexed record is guaranteed to be in the sample.
This problem is sort of an inverse to the efficient sampling problem.
We need to propagate the indices upwards through the query tree.

The next challenge is the outlier index must not require any additional effort to materialize.
We add the condition that the only eligible indices are ones on base relations that are being sampled (ie. we can push the hash operator down to that relation).
Therefore, in the same iteration as sampling, we can also test the threshold and add records to the outlier index.
We formalize the propagation property recursively. 
Every relation can have an outlier index which is a set of attributes and a set of records that exceed the threshold value on those attributes.

\begin{definition}
(OUTLIER INDEX PUSHUP). Define an outlier index to be a tuple of a set of attributes, relation, and a set of records $(A,R,O)$. The outlier index propagates upwards with the following rules:
\begin{itemize}\vspace{-.45em}
\item Base Relations: Outlier indices on base relations are pushed up only if that relation is being sampled.\vspace{-.45em}
\item $\sigma_{\phi}(R)$: Always propagates upwards \vspace{-.45em}
\item $\Pi_{p,(a_2,...,a_k)}(R)$: Propagates upwards if $A$ is in the projection, otherwise null.\vspace{-.45em}
\item $\bowtie_{\phi (r1,r2)}(R_1,R_2)$: New outlier index where $A=A_{r1} \cup A_{r2}$ and $O = \bowtie_{\phi (r1,r2)}(O_1,O_2)$.
\item $\gamma_{e}(R)$: New outlier index where $A=\{e\}$ and $O = \gamma_{e}(O)$.\vspace{-.45em}
\item $R_1 \cup R_2$: Propagates if $A_1 = A_2$, in which case $O = O_1 \cup O_2$.
\item $R_1 \cap R_2$: Propagates if $A_1 = A_2$, in which case $O = O_1 \cap O_2$.
\item $R_1 - R_2$: Propagates if $A_1 = A_2$, in which case $O = O_1 - O_2$.
\end{itemize}
\end{definition}
For all outlier indices that can propagate to the view (ie. the top of the tree), we get a final set $O$ of records. 
This gives us a deterministic set of records in addition to our sample which we can use in query processing.

\subsection{Query Processing with the Outlier Index} 
The outlier index has two uses: (1) we can query all the rows that correspond to outlier rows, 
and (2) we can improve the accuracy of our \emph{aggregation} queries.
To query the outlier rows, we can select all of the rows in the materialized view that are flagged as outliers, and these rows are guaranteed to be up-to-date.

We can also incorporate the outliers into our correction estimates.  
By guaranteeing that certain rows are in the index, we
have to merge two results: one over the outliers and one over the regular records.
For a given aggregation query, let $N$ be the count of records that satisfy the query's condition and $l$ be the number of outliers that satisfy the condition.
Let $v_{reg}$ be the query result for the regular records, and $v_{out}$ is the query result for outliers, then:

\[
 v = \frac{N-l}{N}v_{reg} + \frac{l}{N}v_{out}
\]

We can use this method to improve the accuracy of our correction estimates by calculating $\dans$ 
on the outliers and the regular records separately then averaging them together. 
%See \cite{chaudhuri2001overcoming} for additional query processing details.