\section{Outlier Indexing}\label{outlier}
Sampling is known to be sensitive to outliers \cite{clauset2009power, chaudhuri2001overcoming}.
Power-laws and other long-tailed distributions are common in large datasets\cite{clauset2009power}.
We address this problem using a technique called outlier indexing which has been applied in SAQP \cite{chaudhuri2001overcoming}.
The basic idea is that we create an index of outlier records (records whose attributes deviate from the expected value greatly) and ensure that these records are included in the sample.
However, as this has not been explored in the materialized view setting there are new challenges in using this index for improved result accuracy.

\subsection{Indices on the Base Relations}
In \cite{chaudhuri2001overcoming}, outlier indices are defined on the sampled relation. 
In SVC, we sample the materialized view and only maintain those rows in the sample.
Therefore, there is a problem since the outlier records are not materialized.
To address this problem, we define the outlier index on the base relation.

The first step is that the user selects an attribute of any base relation to index and specifies a threshold $t$ and a size limit $k$.
In a single pass of updates (without maintaining the view), the index is built storing references to the records with attributes greater than $t$.
If the size limit is reached, the incoming record is compared to the smallest indexed record and if it is greater then we evict the smallest record.
The same approach can be extended to attributes that have tails in both directions by making the threshold $t$ a range, which takes the highest and the lowest values.
However, in this section, we present the technique as a threshold for clarity.

To select the threshold, there are many heuristics that we can use.
For example, we can use our knowledge about the dataset to set a threshold.
Or we can use prior information from the base table, a calculation which can be done in the background during the periodic maintenance cycles.
If our size limit is $k$, we can find the records with the top $k$ attributes in the base table as to set a threshold to maximally fill up our index. 
Then, the attribute value of the lowest record becomes the threshold $t$.

\subsection{Adding Outliers to the Sample}
Given this index, the next question is how we can use this information in our materialized views.
We ensure that any row in a materialized view that derives from an indexed record is guaranteed to be in the sample.
This problem is sort of an inverse to the efficient sampling problem.
We need to propagate the indices upwards through the query tree.

The next challenge is the outlier index must not require any additional effort to materialize.
We add the condition that the only eligible indices are ones on base relations that are being sampled (ie. we can push the hash operator down to that relation).
Therefore, in the same iteration as sampling, we can also test the threshold and add records to the outlier index. 
We formalize the propagation property recursively. 
Every relation can have an outlier index which is a set of attributes and a set of records that exceed the threshold value on those attributes.

The main idea is to treat the indexed records as a sub-relation that gets propagated upwards with the maintenance plan.
\begin{definition}[outlier index pushup]
Define an outlier index to be a triple of a set of attributes, relation, and a set of records $(A,R,O)$. The outlier index propagates upwards with the following rules:
\begin{itemize}\vspace{-.45em}
\item Base Relations: Outlier indices on base relations are pushed up only if that relation is being sampled i.e. if the sampling operator can be pushed down to that relation.\vspace{-.45em}
\item $\sigma_{\phi}(R)$: Push up with a new outlier index $(A,\sigma_{\phi}(R),O)$ \vspace{-.45em}
\item $\Pi_{(a_1,...,a_k)}(R)$: Push upwards with new outlier index $(A \cap (a_1,...,a_k), R,O)$.\vspace{-.45em}
\item $\bowtie_{\phi (r1,r2)}(R_1,R_2)$: Push upwards with new outlier index $(A_{r1} \cup A_{r2}, R_1 \bowtie R_2 ,O_1 \bowtie O_2)$.
\item $\gamma_{f,e}(R)$: Recall our earlier notation where the resulting schema of the group-by aggregation was $(e_i,f_i)$. For group-by aggregates, we set $A = \{f_i\}$ and $R = \gamma_{f,e}(R)$. For the outlier index, we do the following steps. (1) Apply the aggregation to the outlier index $\gamma_{f,e}(O)$, (2) for all distinct $e_i$ in $O$ select the row in $\gamma_{f,e}(R)$ with the same $e_i$, and (3) this selection is the new set of outliers $O$. 
\item $R_1 \cup R_2$: Push up with a new outlier index $(A_1 \cap A_2 ,R_1 \cup R_2,O_1 \cup O_2)$. 
\item $R_1 \cap R_2$: Push up with a new outlier index $(A_1 \cap A_2 ,R_1 \cap R_2,O_1 \cap O_2)$.
\item $R_1 - R_2$: Push up with a new outlier index $(A_1 \cup A_2 ,R_1 - R_2,O_1 - O_2)$.
\end{itemize}
\end{definition}

For all outlier indices that can propagate to the view (ie. the top of the tree), we get a final set $O$ of records. 
Given these rules, $O$ is, in fact, a subset of our materialized view $S'$.
Thus, our query processing can take advantage of the theory described in the previous section to incorporate the set $O$ into our results.
In practice, we implement the outlier index not as distinct relation but we add an additional attribute on our sample with a boolean flag true or false if it is an outlier indexed record.

\subsection{Query Processing with the Outlier Index} 
For result estimation, we can think of our sample $\hat{S'}$ and our outlier index $O$ as two distinct parts.
Since $O \subset S'$, our sample is actually a sample restricted to the set $\hat{(S'-O)}$.
The outlier index has two uses: (1) we can query all the rows that correspond to outlier rows, 
and (2) we can improve the accuracy of our \emph{aggregation} queries.
To query the outlier rows, we can select all of the rows in the materialized view that are flagged as outliers, and these rows are guaranteed to be up-to-date.

For (2), we can also incorporate the outliers into our correction estimates.  
For a given query, let $c_{reg}$ be the correction calculated on $\hat{(S'-O)}$ using the technique proposed in the previous section and adjusting the sampling ratio $m$ to account for outliers removed from the sample.
We can also apply the technique to the outlier set $O$ since this set is deterministic the sampling ratio for this set is $m=1$, and we call this result $c_{out}$.
Let $N$ be the count of records that satisfy the query's condition and $l$ be the number of outliers that satisfy the condition.
Then, we can merge these two corrections in the following way:
\[
 v = \frac{N-l}{N}c_{reg} + \frac{l}{N}c_{out}
\]

For the queries in the previous section that are unbiased, this approach preserves unbiasedness.
Since we are averaging two unbiased estimates $c_{reg}$ and $c_{out}$, the linearity of the expectation operator preserves this property.
Furthermore, since $c_{out}$ is deterministic (and in fact its bias/variance is 0), $c_{reg}$ and $c_{out}$ are uncorrelated making the bounds described in the previous section applicable as well.
%sum of uncorrelated unbiased estimates since one is deterministic.

%See \cite{chaudhuri2001overcoming} for additional query processing details.