\section{System Overview}\label{sec-arch}
In this section, we give an overview of the entire architecture of SVC. \reminder{Add a system architecture in this section.}


\subsection{Formalizing View Maintenance as Data Cleaning}
\reminder{I move some text into this section, but have not revised text. I think the basic flow is that 1) you say you want to use SampleClean to solve MV problem, and say what benefits of doing that; 2) you say in order to do that, you have to model view maintenance problem as data cleaning problem, and then formalize this idea; 3) you say three limitations of SampleClean that you have to overcome to address MV problem. }

In SVC, we look at queries on stale materialized views from the perspective of SampleClean.
We can model a stale row in a view as dirty data. \reminder{Should it be a stale row as dirty data or a stale materialized view as dirty data?}
For the data cleaning, there is some procedure (using the updates) to update this row. \reminder{update is not well defined. does it include insertion or deletion?}
For a random sample of stale data \reminder{stale MV?}, we can apply the updates and measure how the updates change a query result and then issue a correction to achieve a result that in expectation is up-to-date. \reminder{since you have already introduced SampleClean in the last paragraph, you can explain this correction idea from the SampleClean perspective}
This model gives the user access to a new tradeoff space: (1) sampling allows for reduced update costs in comparison to a full update, (2) gives better accuracy than no view maintenance.   


To apply the algorithms \reminder{I would not say NormalizedSC is an algorithm. It is more like a query processing method} proposed in SampleClean, we need to formalize this problem as a data cleaning problem.
Using the notation defined in the previous section. 
Let $S$ be a materialized view defined by the relational expression $S_{def}$ a composition of operators defined in Section ?? applied to the database $\mathcal{D}$.
Now suppose the relations in $\mathcal{D}$ have been updated with the correponding set of delta relations $U = \{\Delta R_i\} \cup \{\nabla R_i\}$. \reminder{$R_i$ ?}

$S$ is now \emph{dirty} data, and every query $q$ applied to $S$ will give a dirty result.
As in SampleClean, we take a uniform random sample of ratio $m$ of the dirty data which we call $\hat{S}$.
Based on the operators that we have defined, there are three types of errors that affect $\hat{S}$:
\begin{itemize}
\item A row in $\hat{S}$ needs to be updated.
\item A row in $\hat{S}$ needs to be deleted.
\item To maintain the uniform random sample of ratio $m$ rows need to be added to $\hat{S}$. \reminder{no clear}
\end{itemize}

Based on these data errors, we can define three data cleaning operations to get a cleaned sample of data $\hat{S'}$ (a uniform random sample of ratio $m$ of the up-to-date view $S'$):
\begin{itemize}
\item If an update is needed, update the row.
\item If the row needs to be deleted, delete the row.
\item Add a random sample of ratio $m$ of rows that need to be inserted.
\end{itemize}

\reminder{Add an example}

\iffalse
The key contribution of this work is efficiently materializing $\hat{S'}$, and using the comparison between $\hat{S}$ and $\hat{S'}$ to correct stale queries on the view.
Of course, in some cases, materializing the sample may require equivalent work to updating the entire view, and we explore the cases in which this technique leads to savings in maintenance costs. 
\fi



However, as mentioned in the introduction, this metaphor only goes so far.
Staleness can result in rows in the stale sample that are missing in the up-to-date sample.
Or, it can result in new rows in the up-to-date sample that could not possibly be in the stale sample.
In this work, we add many new contributions not considered in SampleClean: (1) we consider the effect of missing rows by using a hashing-based lineage technique, (2) we generalize our sample procedure to sample from derived relations not just the base relation as in SampleClean, (3) we explicitly consider the effects of outliers on sampling, (4) we extend the work to handle \textbf{SELECT} queries, and (5) we explore optimality of NormalizedSC.

\reminder{It's a little hard to understand these constributions without reading the remaining part of the paper. I would suggest to sumarize three limitations that sampleclean have and say SVC overcomes these limitations. 1) cleaning: no data cleaning; 2) querying: restricted aggregation queries and optimality; 3) sampling: no outlier indexing}

\subsection{System Architecture}
\reminder{I would not call each section as an algorithm, but a component of our system.  }

In this work, we address three distinct problems: (1) query optimization to efficiently find $\hat{S'}$, (2) using $\hat{S}$ and $\hat{S'}$ to calculate an approximate correction for a stale query result, and (3) increased robustness to outliers with outlier indexing.

\subsubsection{Algorithm 1. Efficient Sampling of View Updates \reminder{Have you defined what is ``view updates"?}}
The input of this algorithm is $\hat{S}$ and the output is $\hat{S'}$.
Define a maintenance plan $\mathcal{M}(\mathcal{D},S_{def},\hat{S},U)$ \footnote{For brevity, we will drop the parameters when not ambiguous.} a maintenance strategy (be it incremental maintenance, full recomputation, or a mix) parametrized by the database, the view definition, the stale sample view, and the set of updates. \reminder{Move this definition to Sec 2.1.2}
A maintenance plan is a relational expression the execution of which returns $\hat{S'}$ by appropriately applying the cleaning operations defined in the previous section using information from the view definition and the updates.

A naive, inefficient approach to this problem would be to materialize $S'$ entirely then select those rows that happen to be in the sample.
Instead, we must exploit the fact that we need not materialize every row and do just enough computation to materialize only the rows in $\hat{S'}$.
[This problem defining a sampling operator, which we add to the maintenance plan's query tree, and using relational algebra rules to push this operator as far down the tree as possible.] \reminder{I would suggest not give details but a high-level idea and then point to sec 4.}

\reminder{Add an example}

\subsubsection{Algorithm 2. Query Correction }
Given a query $q$, the stale sample $\hat{S}$, and an up-to-date sample created by the previous procedure $\hat{S'}$.
When $q$ is applied to the full stale view, it gives a stale result of $r$.
We define $c$ a correction, which is a function of $\hat{S}$ and $\hat{S'}$, that gives a corrected result $r-c$. \reminder{Say this is new, and old sampleclean work cannot solve it.}


Like similar restrictions in other sampled-based systems \cite{agarwalknowing}, there are restrictions on the queries $q$ on the view that we can answer.  \reminder{You can first say what kinds of queries that SampleClean consider (see my reminder in the begining of Sec 2.2), and then say in this work, we can support more. }
In this work, we primarily consider non-nested aggregate queries with simple predicates on a single view:
\begin{lstlisting} [mathescape]
SELECT $f(a)$ FROM View 
WHERE Condition(A);
\end{lstlisting}
We also consider correcting stale non-nested select queries of the following form with simple predicates:
\begin{lstlisting} [mathescape]
SELECT * FROM View 
WHERE Condition(A);
\end{lstlisting}
As with all sample estimates, for the estimates to be meaningful, the predicate should not be too selective.

\reminder{Add an example}


\subsubsection{Algorithm 3. Outlier Indexing}
We define an outlier index on base relations of the database $\mathcal{D}$.
This index tracks records whose attributes cross some threshold $t$.
For every row in the view that is derived from a record in the outlier index, we ensure that it is incorporated into the sample.
We explore the conditions under which we can make this guarantee. \reminder{Explain why we need outlier indexing and why it is challenging. Give a high-level idea and then point to Sec 6. }

\subsubsection{Practical Use and Implementation}
In implementation, SVC will work in conjunction with existing defered maintenance or re-calculation approaches.
We envision the scenario where materialized views are being refreshed periodically, for example nightly.
While maintaining the entire view throughout the day may be infeasible, sampling allows the database to scale the cost with the performance and resource constraints during the day.
Then, between maintenance periods, we can provide approximately up-to-date query results for some queries.

\subsection{Example Application: Log Analysis}
\reminder{remove this example and merge it into sec 3.1, 3.2.1, 3.2.2.}

Without getting into the formal details, to illustrate our system and justify our argument about performance improvements, we use the following running example which is a 
simplified schema of one of our experimental datasets (Figure~\ref{example-1}).
Imagine, we are querying logs from a video streaming company. 
These logs record visits from users as they happen and grow over time.
We have two tables, \tbl{Log} and \tbl{Video}, with the following schema:

\begin{lstlisting}[mathescape]
Log(sessionId$\textrm{,}$ videoId$\textrm{,}$ responseTime$\textrm{,}$ userAgent)
Video(videoId$\textrm{,}$ title$\textrm{,}$ duration)
\end{lstlisting}
These tables are related with a foreign-key relationship between
Log and Video, and there is an integrity constraint that every log
record must link to one video in the Video table.

\begin{figure}[ht!] 
\centering
\vspace{-0.75em}
 \includegraphics[width=\columnwidth]{figs/sample-clean-example.png}\vspace{-0.25em}
 \caption{A simplified log analysis example dataset. In this dataset, there are two tables: a fact table representing video views and a dimension table representing the videos.\label{example-1}}
\end{figure}

Consider the following example materialized view, which finds a count of the number of times the video's loading latency was greater than 10\% of the duration of the view:

\vspace{0.5em}

\begin{lstlisting} 
SELECT videoId, 
count(1) AS slowResponseTimes 
FROM Log, Video
WHERE Log.videoID = Video.videoID and
	  responseTime > .1*Video.duration
GROUP BY videoId;
\end{lstlisting}

The user wants to know how many videos repeatedly have slow responses.
\begin{lstlisting} 
SELECT COUNT(1)
FROM AggView
WHERE slowResponseTimes > 100;
\end{lstlisting}
Let us suppose the initial query result is $45$.
There now have been new log records inserted into the Log table making the old result stale.
For example, if our sampling ratio is 5\%, that means for 5\% of the videos (distinct videoID's) we refresh stale slowResponseTimes if necessary.
From this sample, we calculate how many new videos changed from a slowResponseTimes of less than 100ms to times greater than 100ms; let us suppose this answer is $2$.
Since our sampling ratio is 5\%, we extrapolate that $40$ new videos throughout the view should now be included in the count.
This means that we should correct the old result by $40$ resulting in the estimate of $85$.

\iffalse
We add the following operator $\eta_{a_1, m}(R)$ which is the \textbf{hash} operator.
For all tuples in R, this operator applies a hash function whose range is $[0,1]$ to attribute $a_1$ and selects those records with hash value less than or equal to $m$.
%We make two assumptions on this hash operator: (1) \emph{independence} there is no expression in $S_{def}$ that is dependent on the hash operator, and (2) \emph{uniformity} over the domain of possible attribute values the \emph{a priori} probability of including any tuple is the same.
Finally, we use the \emph{query tree} representation to analyze $S_{def}$ where we unravel composed relational operators into a tree of expressions.
Each leaf of the tree is a relation and each node is an operator.



\subsection{Semantics of Query Results}
We should note that there is an implicit design tradeoff in the way we formulated this problem.
By sampling the maintenance plans, our approach is very general with respect to supported views.
On the other hand, we are restricted in the types of queries that we can run.
If we were to sample from the delta relations instead, this tradeoff would be flipped. 
We have a further discussion about this subtlty in Section ??.

A important concern of users is what are the semantics and guarantees on their corrected query results.
In Table ??, we list all of the aggregate queries supported by Apache HiveQL present a taxonomy of result semantics for these queries.
We will detail the corrections to these queries in Section \ref{correction}.
\fi