\section{System Overview}\label{sec-arch}
\subsection{Problem Setting}
%In this paper, we only consider insertions to the base table, see
%\reminder{Extended Paper} for more details on how to model deletions.
\subsubsection{Supported Views}
We apply SVC to three classes of materialized views, Select-Project, Foreign-Key, and Aggregation:
\vspace{1em}

\noindent\textbf{Select-Project Views (\spview): } These views are defined by Select-Project
expressions of the following form:

\begin{lstlisting}
SELECT [col1,col2,...] 
FROM table 
WHERE condition([col1,col2,...]) 
\end{lstlisting}

\vspace{1em}

\noindent\textbf{Foreign-Key Join Views (\fjview): } As an extension to the Select-Project Views, we can support views derived from a Foreign-Key join:

\begin{lstlisting}
SELECT table1.[col1,col2,...], 
table2.[col1,col2,...]
FROM table1, table2 
WHERE table1.fk = table2.fk 
AND condition([col1,col2,...]) 
\end{lstlisting}

\vspace{1em}

\noindent\textbf{Aggregation Views (\aggview): } We also consider views defined by group-by aggregation queries of the following form:

\begin{lstlisting}
SELECT [f1(col1),f2(col2),...] 
FROM table 
WHERE condition([col1,col2,...]) 
GROUP BY [col1,col2,...]
\end{lstlisting}

There are three types of updates that can affect a base table: \insertion, \delete, \update.
We can model \update as a \delete of the old record then an \insertion of a new record with updated values.
In this paper, we present analysis and results for only insertions. 
Insertion-only workloads are increasing common \reminder{Tim will find a citation}.
In Section \ref{sec:del}, we discuss how to modify our query processing to support \delete, which in turn allows us to support \update.

\subsubsection{Supported Queries}
In this paper, we focus on deriving corrections for the three most common aggregation queries on the view \footnote{For ease of presentation, we assume the query does not have a group-by clause, which can be easily extended by treating each group key as an additional condition of the query.} : 
\begin{lstlisting} [mathescape]
SELECT $\sumfunc(a)/\countfunc(a)/\avgfunc(a)$ FROM View 
WHERE Condition(A);
\end{lstlisting}
For these queries, we prove optimality of our approach with respect to estimate variance (Section \ref{subsec:correct-practical}). 
We also provide support for correcting stale Select queries of the following form:
\begin{lstlisting} [mathescape]
SELECT * FROM View 
WHERE Condition(A);
\end{lstlisting}
Since the results of these queries are not numeric, we instead bound the cardinality of the results.
Refer to Section \ref{sec:sel} for a discussion of how to correct Select queries with SVC. 

%\subsubsection{Supported Materialized Views}\label{subsubsec:supported-view}
%We will first introduce the taxonomy of materialized views that can benefit from our approach. 
%In this paper, we analyze and experiment with three classes of views: Select-Project Views, Foreign-key Join Views, and Aggregation Views.
%Our technique can be applied to a broader class of views, please refer to [?] for a full description.


%There is a taxonomy of aggregation views and we discuss different types of aggregate functions (distributive, algebraic, holistic) can be applied in our framework \reminder{Extended Paper}.



%Modeling incremental maintenance as a data cleaning problem gives as a new perspective.
%Staleness in a materialized view row is a type of data error.
%A row 

%When rows in the materialized view are stale

%Frequent incremental maintenance of materialized views can be challenging given system resource constraints.
%Existing materialized view maintenance techniques lie on a spectrum of freshness and performance.
%Immediate maintenance guarantees that query results on the view will always be fresh, while batch maintenance allows for a higher throughput of updates to the base table.
%These two techniques sit at the extremes of the spectrum since they still require that all updates are processed and propagated to the view.



%Thus, our results are never stale; \reminder{This claim is a little strong. Since we do batch job, is it also possible for us to give stale results?} they have some inaccuracy introduced by the sampling ratio but in expectation they are correct.
%Furthermore, we also prove that this correction term is the optimal linear unbiased estimate for SUM, COUNT, and AVG.

\subsection{System Architecture}
Modeling view maintenance as a data cleaning problem gives us a new perspective for addressing staleness.
Insertions to the base table can cause two types of staleness in the view: rows are either out-of-date or missing altogether.
The challenge is to ``clean" the materialized view by updating the out-of-date rows and inserting the missing rows, however this can be very expensive if there are a large number of new records to process.
Suppose, we cleaned a random sample of dirty rows processing only as many of the new insertions as necessary this would potentially reduce the amount of updates, join executions, and aggregates we would need to compute.
From this sample, we can derive a correction to stale query results.

The architecture of SVC is shown in Figure \ref{sys-arch}.
The diagram depicts the following components: (1) we sample the ``update pattern". 
(2) we maintain an outlier index, and (3) we combine the sample and the outlier index to process queries on the stale view.

\begin{figure}[h]
\centering
 \includegraphics[scale=0.35]{figs/sys-arch.pdf}
 \caption{We clean a stale query result by deriving a correction from a sample of up-to-date data. To make this process robust to skewed datasets, we couple sampling with an outlier indexing approach. For aggregation queries, we can guarantee that our results are unbiased and bounded. \label{sys-arch}}
\end{figure}

In implementation, SVC will work in conjunction with existing maintenance or re-calculation approaches.
We envision the scenario where materialized views are being refreshed periodically, for example nightly.
While maintaining the entire view throughout the day may be infeasible, sampling allows the database to scale the cost with the performance and resource constraints during the day.
Then, between maintenance periods, we can provide approximately up-to-date query results for aggregation queries.

\subsubsection{Sampling the Update Pattern}
%Given these materialized views, the first challenge is sampling.
The three classes of views require different sampling techniques since they are affected by updates differently.
For example, insertions to the base table only result in insertions to Select-Project views.
But, for Aggregation Views, insertions to the base table can also result to updates to existing stale rows.
In Section \ref{sampling}, we describe the sampling algorithm and a cost analysis of how much sampling can reduce maintenance costs.

\subsubsection{Outlier Indexing}
We use an outlier index to reduce the sensitivity of our correction estimates to skewed distributions. 
We guarantee that records (or rows in the view derived from those records) 
in the outlier index are also included in the sample.
This can be used to reduce variance in our estimates.
See Section \label{outlier} for details on this component.

\subsubsection{Correcting a Query}
We can use information from the sample to correct stale query results.
For the three most common aggregate functions, \sumfunc, \countfunc, and \avgfunc, we calculate a correction
which is bounded and provably optimal.
Like the sampling, the algorithm to calculate the correction varies between the types of views.
We detail query correction in Section \ref{correction}.

\subsubsection{Example Application: Log Analysis}
To illustrate our approach, we use the following running example which is a 
simplified schema of one of our experimental datasets (Figure ?).
Imagine, we are querying logs from a video streaming company. 
These logs record visits from users as they happen and grow over time.
We have two tables, Log and Video, with the following schema:

\begin{lstlisting}[mathescape]
Log(sessionId$\textrm{,}$ videoId$\textrm{,}$ responseTime$\textrm{,}$ userAgent)
Video(videoId$\textrm{,}$ title$\textrm{,}$ duration)
\end{lstlisting}
These tables are related with a foreign-key relationship between
Log and Video, and there is an integrity constraint that every log
record must link to one video in the video table.

\begin{figure}[t] 
\centering
 \includegraphics[scale=0.33]{figs/sample-clean-example.png}
 \caption{A simplified log analysis example dataset. In this dataset, there are two tables: a fact table representing video views and a dimension table representing the videos.\label{example-1}}
\end{figure}

Consider the following example materialized view \aggview, which stores a result for each video and the maximum time it took for the server to load that video:
\begin{lstlisting} 
SELECT videoId, 
max(responseTime) AS maxResponseTime 
FROM Log 
GROUP BY videoId;
\end{lstlisting}

The user wants to know how many videos had a max response time of greater than 100ms.
\begin{lstlisting} 
SELECT COUNT(1)
FROM AggView
WHERE maxResponseTime > 100
\end{lstlisting}
Let us suppose the initial query result is $15$.
There now have been new log records inserted into to the Log table making the old result of $15$ stale.
For example, if our sampling ratio 5\%, our system maintains a sample of this view.
That means for 5\% of the videos (distinct videoID's) we refresh stale maxResponseTime if necessary.
From this sample, we calculate how many new videos changed from a maxResponseTime of less than 100ms to times greater than 100ms; let us suppose this answer is $2$.
Since our sampling ratio is 5\%, we extrapolate that $10$ new videos throughout the view should now be included in the count, resulting in the estimate of $25$.
In contrast, if we had applied SAQP, we would have counted how many videos in the sample had a max response time of greater than 100ms.