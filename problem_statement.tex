\section{Background}\label{sec-background}

\subsection{Incremental Maintenance}\label{subsec-inc}
Incremental maintenance of materialized views is well studied; see \cite{chirkova2011materialized} for a survey of the approaches. 
Most incremental maintenance algorithms consists of two steps: calculating a ``delta" view,
and ``refreshing" the materialized view with the delta.
More formally, given a base table $T$, a set of updates $U$,
and a view $\textbf{V}_{T}$.
For the ``delta view" step, we apply the view definition to the updates $U$ and we call
the intermediate result a ``delta'' view $\Delta\textbf{V}$.
For the refresh step, given the ``delta'' view, we merge the results with the existing
view $\textbf{V}_{T}^{'}=refresh(\textbf{V}_{T},\Delta\textbf{V})$.
The details of the refresh operation depend on the view definition.
(See \cite{chirkova2011materialized}).

%Remove this to save some space
%This is also called a \emph{change propagation formula} in some literature, 
%especially on algebraic representations of incremental view maintenance.\reminder{refs?}

%In this work, we address three types of materialized views: Select-Project, Aggregation, and
%Foreign-Key Join views; and four common aggregation queries on these
%views: SUM, COUNT, AVG, and VAR. We further analyze 
%only insertions into the database and defer analysis of updates
%and deletions for future work.

\subsection{Maintenance Strategies}
There are two principal incremental maintenance strategies: immediate and deferred. 
In immediate maintenance, as soon as the base table is updated, 
any derived materialized view is also updated.
Immediate maintenance has an advantage that queries on the materialized view are always up-to-date, 
however it can be very expensive.
This scheduling strategy places a bottleneck on updates to the base table.
Furthermore, especially in a distributed setting, record-by-record 
maintenance cannot take advantage of the benefits of consolidating communication overheads by batching.

To address these challenges, deferred maintenance is alternative solution.
The main idea of deferral is to avoid maintaining the view immediately and schedule an update at a more convenient time either in a pre-set way or adaptively.
In deferred maintenance approaches, the user often accepts some degree of staleness for additional flexibility in scheduling.
For example, views can be updated at night when the system can use more resources to process the updates without affecting a critical application.
However, this also means that during the day the materialized view becomes increasingly stale as it was computed the night before.

These costs can also be deferred to query execution time.
In particular, we highlight a technique called lazy maintenance which applies updates to the view only when a user's query requires a row \cite{zhou2007lazy}.
Both lazy maintenance and immediate maintenance hit a bottleneck when there rapid updates making these approaches impractical.


%While it ensures that query results are never stale, lazy maintenance potentially shifts much of the computational cost to query execution time.

%It is during this period of staleness we see an opportunity to apply our approach.
%Sampling gives the user an additional parameter that allows them to scale the maintenance cost to meet system resource constraints.
%Instead of stale query results during the day, the user can maintain as much their system allows them to do so, and for aggregation queries
%get results that are approximately up-to-date.
%This process is reset during the normal view maintenance cycle.



%Immediate maintenance introduces a bottleneck on updates to the base table and lazy maintenance introduces a bottleneck during query execution,
%and rapid updates can make these approaches impractical.
%As a consequence, periodic maintenance or recalculation is often the most feasible solution.

\subsection{Data Cleaning}
Much of data cleaning research focuses on improving query accuracy on dirty datasets.
For example, designing rules or algorithms to remove or correct erroneous records \cite{rahm2000data}.
Recent work has begun to consider the costs of data cleaning as well as how to budget data cleaning effort.
%The Data Wrangler project argues that rules to correct the entire dataset can be learned from a small set of training examples \cite{kandel2011wrangler}.
The SampleClean project framework cleans a sample of data, and then bounds the results of aggregate queries on dirty datasets with respect to the clean data \cite{wang1999sample}.

One of the algorithms in SampleClean, takes a random sample of dirty records, applies data cleaning, and learns how to correct a query applied to the dirty data.
Instead of modeling data error on the base table, SampleClean considers how dirtiness affects queries on the data.
In SVC, we look at queries on stale materialized views from this perspective.
As materialized views are different problem setting, there are new challenges such as sampling from changing base tables, selection queries, and considering the effects of outliers.

\subsection{SAQP}
Estimating the results of aggregate queries from samples has been
well studied in a field called Sample-based Approximate Query Processing
(SAQP) \cite{OlkenR86,AgarwalMPMMS13}.
Our approach differs from SAQP as we use a sample to correct a query rather than directly estimating the query result.
The SAQP approach to this problem, would be to
estimate the result directly from the maintained sample \cite{joshi2008materialized}.
We found that estimating
a correction and leveraging an existing deterministic result led
to lower variance results on real datasets (see Section \ref{exp}). 


