\section{Introduction}
Materialized views, cached pre-computed query results, are used to optimize query processing on large datasets \cite{gupta1995maintenance, chirkova2011materialized, halevy2001answering}.
Materialization and related concepts such as selecting which queries to materialize
have been well studied in recent research \cite{zaharia2012resilient,lefevre2014opportunistic, bailis2014scalable, perez2014history}.
This research has further expanded beyond the SQL setting \cite{nikolic2014linview} and 
has shown promising results when applied to numerical linear algebra and machine learning.
However, when derived from frequently changing tables,
materialized views face the obvious challenge of \emph{staleness} where the pre-computed results need to be updated to reflect the changes in the base tables.
To avoid expensive recalculation, incrementally updating materialized views,
also called incremental maintenance, has been well studied \cite{gupta1995maintenance, chirkova2011materialized}.

Unfortunately, in many desired applications, incremental view maintenance for every incoming update can be very costly. 
When the base tables change rapidly, the database system has to propagate each update to all of the materialized views.
Consequently, there are many techniques that defer updating the views to a later time or trigger the updates only when neccessary \cite{chirkova2011materialized, zhou2007lazy}.
Deferral allows for many advantages such as batching updates together amortize overheads and scheduling updates at times when there are more system resources available eg. at night.
Deferral strategies provide increased flexibility to meet the resource constraints of the system, but may not guarantee that the views will always be up-to-date.
When the materialized views are out-of-date during the maintenance gaps, queries issued to the view can have \emph{stale} results. 

In this work, we address the incremental maintenance problem and the problem of stale results from a different perspective.
We explore whether refreshing stale rows in a materialized view can be modeled as data cleaning problem and whether stale query results can be ``cleaned".
While much of the data cleaning literature focuses on improving query accuracy on dirty datasets,
there has been an increasing trend of considering the costs of data cleaning \cite{wang1999sample}.
In particular, these approaches clean a small, representative sample of records and then use that information to extrapolate results for an entire dataset.
This new perspective raises an intruiging possibility, namely, that staleness can be modeled as a type of data error, 
and perhaps, we can correct stale query results by observing how the updates affect a small sample of records; 
avoiding the need to maintain the entire materialized view.
While this approach introduces approximation error inherrent to sampling, this error for aggregate queries on the materialized view such as SUM, COUNT, and AVG, 
can be probabilistically bounded within confidence intervals.
Existing techniques allow the user to control the freshness of queries by chosing maintenance parameters (eg. nightly maintenance vs. hourly maintenance) based on prior experience, however, without bounds on the results, a burst of updates can lead to unexpected changes in query accuracy.
On the other hand, our approach gives results that are, in expectation, always fresh and the user controls the tightness of the bound with the sampling ratio.
%The SampleClean project [?] studied a related problem of bounding aggregate queries on dirty datasets but did not consider materialized views or the effect of missing records.

Our approach has three components: (1) sampling, (2) outlier indexing, and (3) correction. In (1), we sample the updates to the view in a way that ensures that the sample is representative of the up-to-date data. Updates can affect different classes of views in a variety of ways, and we describe this process as sampling the ``update pattern". For example, in views derived from only Select and Project operations, inserted records to the base table result in insertions to views. However, inserted records can result in both insertions and updates to views defined by aggregation operations. (2) Sampling has the potential to mask outliers, and in fact, it is known
heavy-tailed distributions are poorly approximated from samples \cite{chaudhuri2001overcoming}.
In this framework, we utilize a technique called outlier indexing \cite{chaudhuri2001overcoming}, which guarantees that rows in the materialized view derived from an ``outlier" record (one that has abnormal attribute values) is contained in the sample.
Coupling outlier detection with sampling has an interesting implication; not only can we answer exact selection queries on the outliers, but
the information from the outliers can potentially improve query accuracy or likewise reduce the number of needed samples.
Finally, in (3) we use the sampled update pattern and the outlier index to derive a correct aggregate queries on stale materialized views.
From the sample, we estimate how much the updates affect the query in question and we use this estimate to adjust the query result when applied to a stale view.

What is particularly interesting is that our approach can be implemented with a relatively small overhead: at maintenance time the generation of random numbers to build the sample, and at query execution time single pass over a small sample of data to estimate a correction for the query.
Consequently, sampling can significantly save on maintenance costs and give a flexible tradeoff between accuracy and performance.

To summarize, existing literature proposes the following approaches for this problem: 
\vspace{1em}

\noindent\textbf{Re-calculation: }
The most basic solution to address out-of-date materialized views is to periodically 
recalculate the entire view when the base tables have been updated (ie. re-execute the query on the entire dataset).
This approach can be very inefficient especially when the updates to the base table have only a small effect on the pre-computed result.
On the other hand, this approach requires no additional processing when records in the base table are updated.
For example, we may have user activity logs or sensors constantly feeding data to be inserted into our base table and incremental maintenance 
may place a bottleneck on each insertion as derived views need to be updated.
Furthermore, this approach is very easy to implement especially in systems such as Apache Spark or Hive which do not support
selective updates. 

\vspace{1em}

\noindent\textbf{Immediate Incremental Maintenance: }
Another possible solution is maintaining the view \emph{immediately}, that is, for every incoming update
immediately propagate the changes to the materialized view.
This solution guarantees that the view will always be up-to-date, but this can be very costly.
Updating the views becomes a bottleneck for each update and limits the write-throughput to the base table.

\vspace{1em}

\noindent\textbf{Periodic or Deferred Maintenance: }
It may be infeasible to keep the materialized view up-to-date for every incoming update.
One solution is to defer the maitenance to a time when more resources are avaible, eg. nightly.
Depending on the deferral peiod, these approaches can lead to long periods of stale query results.
Like periodic re-calculation, this removes the bottleneck for updates to the base table.

\vspace{1em}

\noindent\textbf{SAQP: }
Estimating the results of aggregate queries from samples has been
well studied in a field called Sample-based Approximate Query Processing
(SAQP). On the other hand, our approach differs from SAQP as we look to
approximately correct a query rather than directly estimating the query result.
In other words, we use a sample of up-to-date data to understand how to compensate for the
staleness. The SAQP approach to this problem, would be to
estimate the result directly from the maintained sample; a sort of
SAQP scheme on the sample of the view \cite{joshi2008materialized}. We found that estimating
a correction and leveraging an existing deterministic result lead
to lower variance results on real datasets (see Section \ref{exp}). We analyze
the tradeoffs of these techniques in the following sections.

\vspace{1em}

In the space of existing approahces, our system lies in between freshness guarantees of immediate maintenance and the performance of deferred maintenance.
The user sets the sampling ratio to meet either their desired performance and throughput level or accuracy of their query results.
Our proposed approach will be complementary to a periodic maintenance or re-calculation approach.
We envision the scenario where materialized views are being refreshed periodically eg. nightly.
While maintaining the entire view throughout the day may be infeasible, sampling allows the database to scale maintenance with the performance and resource constraints during the day.
Then, between maintenance periods, we can provide approximately up-to-date query results for aggregation queries.

\iffalse
 These two pieces can be costly in different
applications. (1) In distributed environments where the view is partitioned
over a cluster, incremental view maintenance often neccesitates communicating
the delta view. (2) Systems such as Apache Spark, Cloudera Impala,
and Apache Tez {[}?{]} offer materialized view support, however, are
not optimized for selective updates nor have native support for indices.
This can lead to high maintenance costs in applications where the
views are derived from joins that are not aligned with the partitioning
of the base tables. (3) Base data is often raw requiring pre-processing
such as string processing, deserialization, and formatting; all of
which can can be expensive to run on a large number of updates. 



Querying a stale view is similar to problems studied in data cleaning{[}?{]}.
When databases are dirty, query results can be arbitrarily wrong.
Data cleaning is used to remove data errors but this can be very costly either 
requiring machine learning to classify errors or even human intervention.
SampleClean is a query processing framework that answers aggregate
queries on dirty datasets by applying potentially expensive cleaning
techniques to just a sample. The results, while approximate, are bounded
with respect to the clean data and the system offers a flexible tradeoff
between cleaning cost and result accuracy. Similarly, a stale row
and an expensive incremental maintenance scheme, mirrors the problem
setting studied in SampleClean. 

In this paper, we propose a data cleaning approach for approximate,
bounded aggregation queries on stale views. Instead of maintaining
the entire view, we maintain only a small sample of the view. Then
given an aggregation query on this view, from this small sample, we
can estimate how the updates affect the query result. We apply this
estimate to correct the dirty aggregation query result on the stale
data. We call this approach \emph{approximate query correction}. 
These corrections are provably bounded, in contrast to the unbounded stalness,
and the sampling gives a flexible tradeoff to meet performance constraints such as throughput.
Sampling helps reduces both bottlenecks in view maintenance, delta
view calculation and view updating, as it reduces the number of updates
that need to processed and then written.

Another relevant concept from data cleaning is outlier detection {[}?{]}.

In this work, we propose an outlier indexing framework that guarantees that
rows in the materialized view derived from an ``outlier" record, one with
an abnormal attribute value, are included in the sample.

In summary, our contributions are as follows:
\begin{itemize}
\item We present a query processing framework that corrects aggregation queries on stale
views using a sample of up-to-date data.
\item We couple this approach with an oultier indexing framework that allows
for selection queries on outliers and we show both analytically and empirically that 
this can improve query accuracy.
\item We evaluate our approach on two systems, Apache SparkSQL and MySQL,
and discuss how the different systems affect performance performance
parameters.
\end{itemize}
\fi
