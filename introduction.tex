\section{Introduction}
Database systems increasingly use materialized views, storing a pre-computed
query result, to speed up complex queries on large datasets {[}?{]}. 
Due to the decreasing cost of memory, in-memory materialization 
has had much interest in recent research [?] and algorithms
to select materialized views have also been well studied [?].
Materialized view research has further expanded beyond the SQL setting [?] and 
recent work has shown promising results when applied to 
numerical linear algebra and machine learning.
However, when derived from frequently changing tables,
materialized views face the obvious challenge of \emph{staleness}.
Incrementally updating the materialize view,
also called incremental maintenance, has been well studied {[}?{]}.

Unfortunately, in many desired applications, incremental view maintenance
can be very costly. 
This cost breaks down into two components: applying
the view definition to a batch of updates, and then writing the ``delta''
view to the out-of-date view.
When the base tables change rapidly, the database has to propagate these rapid changes to
all of the materialized views.
Due these costs, defering and scheduling view maintenance is a subject of active research including a 
variety of techniques such as batch maintenance {[}?{]} and lazy maintenance {[}?{]}. 
These techniques provide increased flexibility to meet the throughput demands of the system, but 
often tradeoff \emph{freshness} guarantees.
Between maintenance periods queries on the view may have stale results.

In this work, we address the incremental maintenance problem from a different perspective.
We explore whether the problem of refreshing stale rows in a materialized view can be modeled as data cleaning problem.
While much of data cleaning literature focuses on improving query accuracy on dirty datasets,
there has been an increasing trend of considering the costs of data cleaning [?].
In particular, these approaches clean a small, representative sample of records and then use that information to extrapolate results for an entire dataset.
This new perspective raises an intruiging possibility, namely, that staleness can be modeled as a type of data error 
and perhaps, we can correct stale query results by observing how the updates affect a small sample of records; 
avoiding the need to maintain the entire materialized view.
While this approach introduces approximation error inherrent to sampling, this error for aggregate queries such as SUM, COUNT, and AVG, 
can be probabilistically bounded returing results within confidence intervals.
Existing techniques allow the user to control the freshness of queries by chosing maintenance parameters (eg. nightly maintenance vs. hourly maintenance) based on prior experience, however, without bounds on the results, a burst of updates can lead to unexpected changes in query accuracy.
On the other hand, our approach gives results that are, in expectation, always fresh and the user controls the tightness of the bound with the sampling ratio.
%The SampleClean project [?] studied a related problem of bounding aggregate queries on dirty datasets but did not consider materialized views or the effect of missing records.

Our approach has three components: (1) sampling, (2) outlier indexing, and (3) correction. In (1), we sample the updates to the view in a way that ensures that the sample is representative and contains up-to-date data. Updates can affect different classes of views in a variety of different ways, and we describe this process as sampling the ``update pattern". For example, in views derived from only Select and Project operations, inserted records to the base table result in insertions to views. However, inserted records can result in both insertions and updates to views defined by aggregation operations. (2) Sampling has the potential to mask outliers, and in fact, it is known
heavy-tailed distributions are poorly approximated from samples {[}?{]}.
In this framework, we utilize a technique called outlier indexing [?], which guarantees that rows in the materialized view derived from an ``outlier" record (one that has abnormal attribute values) is contained in the sample.
Coupling outlier detection with sampling has an interesting implication; not only can we answer exact selection queries on the outliers, but
the information from the outliers can potentially improve query accuracy or likewise reduce the number of needed samples.
Finally, in (3) we use the sampled update pattern and the outlier index to derive a correct aggregate queries on stale materialized views.
From the sample, we estimate how much the updates affect the query in question and we use this estimate to adjust the query result when applied to a stale view.

What is particularly interesting is that our approach can be implemented with a relatively small overhead: at maintenance time the generation of random numbers to build the sample, and at query execution time single pass over a small sample of data to estimate a correction for the query.
Consequently, sampling can significantly save on maintenance costs and give a flexible tradeoff between accuracy and performance.
For comparision, we existing literature proposes the following approaches for this problem: 
\vspace{1em}

\noindent\textbf{Periodic or Deferred Maintenance: }
It may be infeasible to keep the materialized view up-to-date for every incoming update.
One solution is to defer the maitenance to a time when the system is less active, eg. nightly [?].
Depending on the deferral peiod, these approaches can lead to long periods of stale query results.

\vspace{1em}

\noindent\textbf{Re-calculation: }
Along the same lines as periodic maintenance, another approach 
for up-to-date results is to avoid incremental maintenance altogether.
In this approach, one would periodically re-calculate the views.
This approach allows for the highest throughput in terms of records written, but can
similarly suffer from long periods of stale data.
This approach is may be preferred in systems such as Apache Spark or Hive which do not support
selective updates. 

\vspace{1em}

\noindent\textbf{SAQP: }
Estimating the results of aggregate queries from samples has been
well studied in a field called Sample-based Approximate Query Processing
(SAQP). On the other hand, our approach differs from SAQP as we look to
approximately correct a query rather than directly estimating the query result.
In other words, we use a sample of up-to-date data to understand how to compensate for the
staleness. The SAQP approach to this problem, would be to treat aggregate
queries on views as nested queries and then apply them to a sample
of the base data {[}?{]}. Another potential technique would be to
estimate the result directly from the maintained sample; a sort of
SAQP scheme on the sample of the view. We found that empricially estimating
a correction and leveraging an existing deterministic result lead
to lower variance results on real datasets (see Section ?). We analyze
the tradeoffs of these techniques in the following sections.

\vspace{1em}

Our proposed approach will work in conjunction with existing maintenance or re-calculation approaches.
We envision the scenario where materialized views are being refreshed periodically eg. nightly.
While maintaining the entire view throughout the day may be infeasible, sampling allows the database to scale maintenance with the performance and resource constraints during the day.
Then, between maintenance periods, we can provide approximately up-to-date query results for aggregation queries.









\iffalse
 These two pieces can be costly in different
applications. (1) In distributed environments where the view is partitioned
over a cluster, incremental view maintenance often neccesitates communicating
the delta view. (2) Systems such as Apache Spark, Cloudera Impala,
and Apache Tez {[}?{]} offer materialized view support, however, are
not optimized for selective updates nor have native support for indices.
This can lead to high maintenance costs in applications where the
views are derived from joins that are not aligned with the partitioning
of the base tables. (3) Base data is often raw requiring pre-processing
such as string processing, deserialization, and formatting; all of
which can can be expensive to run on a large number of updates. 



Querying a stale view is similar to problems studied in data cleaning{[}?{]}.
When databases are dirty, query results can be arbitrarily wrong.
Data cleaning is used to remove data errors but this can be very costly either 
requiring machine learning to classify errors or even human intervention.
SampleClean is a query processing framework that answers aggregate
queries on dirty datasets by applying potentially expensive cleaning
techniques to just a sample. The results, while approximate, are bounded
with respect to the clean data and the system offers a flexible tradeoff
between cleaning cost and result accuracy. Similarly, a stale row
and an expensive incremental maintenance scheme, mirrors the problem
setting studied in SampleClean. 

In this paper, we propose a data cleaning approach for approximate,
bounded aggregation queries on stale views. Instead of maintaining
the entire view, we maintain only a small sample of the view. Then
given an aggregation query on this view, from this small sample, we
can estimate how the updates affect the query result. We apply this
estimate to correct the dirty aggregation query result on the stale
data. We call this approach \emph{approximate query correction}. 
These corrections are provably bounded, in contrast to the unbounded stalness,
and the sampling gives a flexible tradeoff to meet performance constraints such as throughput.
Sampling helps reduces both bottlenecks in view maintenance, delta
view calculation and view updating, as it reduces the number of updates
that need to processed and then written.

Another relevant concept from data cleaning is outlier detection {[}?{]}.

In this work, we propose an outlier indexing framework that guarantees that
rows in the materialized view derived from an ``outlier" record, one with
an abnormal attribute value, are included in the sample.

In summary, our contributions are as follows:
\begin{itemize}
\item We present a query processing framework that corrects aggregation queries on stale
views using a sample of up-to-date data.
\item We couple this approach with an oultier indexing framework that allows
for selection queries on outliers and we show both analytically and empirically that 
this can improve query accuracy.
\item We evaluate our approach on two systems, Apache SparkSQL and MySQL,
and discuss how the different systems affect performance performance
parameters.
\end{itemize}
\fi
